# @package _global_

# to execute this experiment run:
# python train.py experiment=GSE90073_lstm

defaults:
  - override /data: GSE90073
  - override /model: lstm
  - override /callbacks: default
  - override /trainer: default
  - override /logger: wandb

# LSTM for GSE90073 classification

tags: ["GSE90073", "lstm", "sequence", "case_control"]

seed: 12345

trainer:
  min_epochs: 10
  max_epochs: 100
  gradient_clip_val: 1.0
  
callbacks:
  early_stopping:
    monitor: "val/loss"
    patience: 5
    mode: "min"
  
  model_checkpoint:
    monitor: "val/acc"
    mode: "max"
    save_top_k: 3
    save_last: true

model:
  num_classes: 2
  optimizer:
    lr: 0.001
    weight_decay: 0.0001
  scheduler:
    mode: min
    factor: 0.5
    patience: 5
  net:
    window_size: 50
    hidden_size: 128
    num_layers: 2
    output_size: 2
    dropout: 0.3
  compile: false

logger:
  wandb:
    name: "GSE90073-LSTM-2Layer-h128-w50-bs32"
    tags: ${tags}
    group: "GSE90073_classification"
  aim:
    experiment: "GSE90073_lstm"