# @package _global_

# to execute this experiment run:
# python src/train.py experiment=mental_transformer_cnn

defaults:
  - override /data: mental
  - override /model: transformer_cnn
  - override /callbacks: default
  - override /trainer: cpu
  - override /logger: wandb

# Transformer-CNN (DeepPlantCRE-inspired) for mental health classification
# Combines transformer's global context with CNN's local pattern extraction

tags: ["mental", "transformer_cnn", "transformer", "cnn", "hybrid", "case_control"]

seed: 42

trainer:
  min_epochs: 10
  max_epochs: 100
  gradient_clip_val: 1.0
  
callbacks:
  early_stopping:
    monitor: "val/loss"
    patience: 5
    mode: "min"
  
  model_checkpoint:
    monitor: "val/auroc"
    mode: "max"
    save_top_k: 3
    save_last: true
    filename: "epoch_{epoch:03d}_auroc_{val/auroc:.4f}"

logger:
  wandb:
    name: "Mental-TransformerCNN-dm${model.net.d_model}-nhead${model.net.nhead}-cnn${model.net.cnn_channels}"
    tags: ${tags}
    group: "mental_classification"
    notes: "Transformer-CNN: DeepPlantCRE-inspired hybrid combining global transformer context with hierarchical CNN features"
  aim:
    experiment: "mental_transformer_cnn"
