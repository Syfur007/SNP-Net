defaults:
  - scheduler: reduce_lr_on_plateau

_target_: src.models.module.LitModule

# Number of classes (2 for binary classification)
num_classes: 2

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0001
  weight_decay: 0.0
  betas: [0.9, 0.999]

net:
  _target_: src.models.components.deepplantcre_net.DeepPlantCRENet
  num_snps: 1000  # DNA sequence length (1000 bp upstream + 500 bp downstream of TSS)
  encoding_dim: 4  # One-hot encoding dimension (A, C, G, T)
  d_model: 4  # Transformer embedding dimension (fixed in DeepPlantCRE)
  nhead: 1  # Number of attention heads (fixed to 1 in DeepPlantCRE)
  num_transformer_layers: 1  # Single transformer layer (fixed in DeepPlantCRE)
  d_ff: 2048  # Feed-forward dimension in transformer
  cnn_channels: [64, 128, 32]  # Fixed channel progression in DeepPlantCRE
  dense_dims: [256, 128]  # Hidden dimensions for dense layers
  dropout: 0.25  # Fixed dropout rate in DeepPlantCRE
  output_size: 2  # Binary classification (CrossEntropyLoss expects 2 classes)
  use_gradient_checkpointing: false

# compile model for faster training with pytorch 2.0
compile: false
