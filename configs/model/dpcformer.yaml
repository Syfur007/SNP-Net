defaults:
  - scheduler: reduce_lr_on_plateau  # Options: cosine_annealing, cosine_annealing_warm_restarts, step_lr, reduce_lr_on_plateau

_target_: src.models.module.LitModule

# Number of classes (2 for binary case/control classification)
num_classes: 2

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.0001
  betas: [0.9, 0.999]

net:
  _target_: src.models.components.dpcformer_net.DPCformerNet
  num_snps: 1000  # Number of SNPs to use for sequence creation (matches GSE139294 feature selection)
  encoding_dim: 1  # 1 for single value encoding (0, 1, 2)
  hidden_dim: 128  # Hidden dimension for attention
  num_heads: 8  # Number of attention heads
  num_cnn_layers: 3  # Number of CNN layers
  dropout: 0.3  # Dropout rate
  output_size: 2  # Number of output classes

# compile model for faster training with pytorch 2.0
compile: false
